{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlwctfUSRaacACaHTn1CQw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AqueeqAzam/deep-and-smart-guidance-of-neural-networks-and-deep-learning/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Deep learning`\n",
        "\n",
        "It is a method in artificial intelligence (AI) that teaches computers to process data in a way that is inspired by the human brain.\n",
        "\n",
        "input + weight -> summation and bias -> activation function -> output\n",
        "\n",
        "x1*w1 -> sum(xiwi+bias) + f(x) -> output"
      ],
      "metadata": {
        "id": "gNXBo6Mq1TYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "boieuy1ZWWAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Neuron and neural networks`\n",
        "\n",
        "Human brain cells, called neurons (perceptron), form a complex, highly interconnected network and send electrical signals to each other to help humans process information."
      ],
      "metadata": {
        "id": "CQwjvPRC182H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Types of neural network`\n",
        "\n",
        "perceptron, Feed Forward Network, Multi-layer Perceptron(ANN), Radial Based Network, CNN, RNN, Long Short-term memeory network"
      ],
      "metadata": {
        "id": "LZvIsfvjJZxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Single layer neural network (perceptron)`\n",
        "\n",
        "# y = f(Σ w_i * x_i + b)\n",
        "\n",
        "Σ (w_i * x_i): This part calculates the weighted sum.\n",
        "\n",
        "b: The bias term (b) is added to the weighted sum. This allows the neuron to learn even when the input values are all zero."
      ],
      "metadata": {
        "id": "Ujn2xvRoKaOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8nC9OAxRX4gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0hnHOaVzxKW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AqueeqAzam/data-science-and-machine-learning-datasets/main/students-placement.csv\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "sns.scatterplot(x = df['cgpa'], y = df['iq'], data = df, hue='placed')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0xk4mrJLO4Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:, :-1]\n",
        "y = df['placed']\n"
      ],
      "metadata": {
        "id": "cPwdeFNNRBvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "pr = Perceptron(alpha=0)\n",
        "pr.fit(x_train, y_train)\n",
        "\n",
        "pr.score(x_train, y_train)*100\n",
        "\n",
        "placed = pr.predict([[3.5, 11, 0]])\n",
        "print('Student result', placed)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3jZKFdy8RVZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Multi layer perceptron (ANNs)`\n",
        "\n",
        "ANNs (Artificial Neural Networks) are helpful for solving complex problems."
      ],
      "metadata": {
        "id": "E42JxWUYTc1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AqueeqAzam/data-science-and-machine-learning-datasets/main/business-case-study.csv\")\n",
        "df.head(5)\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "# scaling the data\n",
        "num_col = df.select_dtypes(include=np.number).columns\n",
        "x = df[num_col]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[num_col] = scaler.fit_transform(x)\n",
        "\n",
        "# splitting the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train.shape, x_test.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMyIzCB7GWRB",
        "outputId": "094a9f2f-8696-4a5b-f49f-e255978c80e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 11), (2000, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ann = Sequential()\n",
        "\n",
        "# units=6: This argument specifies the number of neurons in this dense layer.\n",
        "ann.add(Dense(units=6, activation='relu', input_dim=11))\n",
        "ann.add(Dense(units=4, activation='relu'))\n",
        "ann.add(Dense(units=2, activation='relu'))\n",
        "ann.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# x_train: This represents your training data, y_train: These are the desired outputs or targets,\n",
        "\n",
        "# Batch Size is a crucial hyperparameter that determines the number of training examples used to update the model's weights and biases in each iteration during training.\n",
        "\n",
        "# an epoch refers to a single complete pass through your entire training dataset during the training process.\n",
        "\n",
        "ann.fit(x_train, y_train, batch_size=64, epochs=40)\n",
        "\n",
        "pre = ann.predict(x_test)\n",
        "\n",
        "pre\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre = (pre > 0.5).astype(int)\n",
        "\n",
        "acc_score = accuracy_score(y_test, pre)\n",
        "print('Accuracy of testing model is:', acc_score)\n",
        "\n",
        "\n",
        "# checking accuracy of training model\n",
        "pre1 = ann.predict(x_train)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre1 = (pre1 > 0.5).astype(int)\n",
        "\n",
        "acc_score1 = accuracy_score(y_train, pre1)\n",
        "print('Accuracy of training model is:', acc_score1)\n"
      ],
      "metadata": {
        "id": "OXIk3nBawhP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward and Forward Propogation\n",
        "\n",
        "`Backward Propagation:` It is the process of moving from right (output layer) to left (input layer).\n",
        "\n",
        "`Forward propagation:` It is the way data moves from left (input layer) to right (output layer) in the neural network. A neural network can be understood by a collection of connected input/output nodes."
      ],
      "metadata": {
        "id": "L5JZR4FAW-gP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function\n",
        "\n",
        " An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron's input to the network is important or not in the process of prediction using simpler mathematical operations.\n",
        "\n",
        " Linear: f(x) = x, range: - infi to +infi\n",
        "\n",
        " Non-linear: f(x) = x^2\n",
        "\n",
        " Sigmoid: pi(z) = 1/1+e^-z\n",
        "\n",
        " tang: f(x) = e^x + e^-x / e^x - e^-x\n",
        "\n",
        " ReLU: f(x) = { 0 for x<0 or x for x>= 0 }\n",
        "\n"
      ],
      "metadata": {
        "id": "S2ANv0zLX_bU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function\n",
        "\n",
        "The loss function guides the training process by indicating how much the network's outputs differ from the ground truth.\n",
        "\n",
        "By minimizing the loss function through an optimization algorithm (e.g., gradient descent), the neural network learns to adjust its internal weights and biases to produce more accurate predictions on unseen data.\n",
        "\n",
        "`For classification:`\n",
        "\n",
        "Binary Cross-Entropy: Used for problems with two output classes (e.g., cat vs. dog image classification).\n",
        "\n",
        "Categorical Cross-Entropy: Used for multi-class classification problems (e.g., classifying handwritten digits 0-9).\n",
        "\n",
        "`Regression:`\n",
        "\n",
        "Mean Squared Error (MSE): Calculates the average squared difference between the predicted continuous values and the actual target values.\n",
        "\n",
        "Mean Absolute Error (MAE): Similar to MSE, but it calculates the average absolute difference instead of squared differences.\n",
        "\n"
      ],
      "metadata": {
        "id": "CljL0sxXe7d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer\n",
        "\n",
        "Its primary function is to adjust the weights and biases of the network's neurons iteratively to minimize a predefined loss function.\n",
        "\n",
        "`Here's a breakdown of how optimizers work:`\n",
        "\n",
        "`Loss Function:` During training, the network's predictions are compared to the actual targets (ground truth) using a loss function.\n",
        "\n",
        "`Gradient Descent:` Optimizers utilize a technique called gradient descent to update the network's weights and biases.\n",
        "\n",
        "`Optimizer's Role:` The optimizer uses the calculated gradients to adjust the weights and biases in a way that minimizes the loss function over time.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1A-yTDswgXeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# improve performance of neural network\n",
        "\n",
        "`Quality and Quantity:` Ensure you have high-quality, labeled data relevant to your task.\n",
        "\n",
        "`Preprocessing:` Clean and normalize your data. This often involves handling missing values, scaling features to a common range.\n",
        "\n",
        "`Complexity:` Experiment with different network architectures (number of layers, neurons per layer, activation functions) to find a suitable balance between complexity and overfitting.\n",
        "\n",
        "`Loss Function and Metrics:` Closely monitor the training and validation loss during training.\n",
        "\n",
        "`Regularization:` Techniques like L1/L2 regularization penalize large weights, preventing the network from overfitting by encouraging simpler models.\n",
        "\n",
        "`Learning Rate:` The learning rate controls the magnitude of weight updates during training.\n",
        "\n",
        "`Optimizer:` Choose an appropriate optimizer based on your problem type and network architecture.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9cPfKsuMiqlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Overfitting`\n",
        "\n",
        "Overfitting is a common challenge in neural network training. It occurs when a network memorizes the specific details of the training data too closely, hindering its ability to generalize well to unseen examples.\n",
        "\n",
        "`if training accuracy > testing accuracy:`\n",
        "      return overfitting\n",
        "\n",
        "`if training accuracy = testing accuracy`\n",
        "     retrun bestfitting\n",
        "\n",
        "`if not one of them:`\n",
        "    retrun underfitting\n"
      ],
      "metadata": {
        "id": "rQSLU7ilcXZw"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AqueeqAzam/data-science-and-machine-learning-datasets/main/students-placement.csv\")\n",
        "df.head(4)\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "# Select only numerical columns for scaling\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "x = df[numerical_cols]\n",
        "\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit_transform(x)\n",
        "\n",
        "x = pd.DataFrame(ss.fit_transform(x), columns=x.columns)\n",
        "x\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "ann = Sequential()\n",
        "# Update input_dim to match the number of features in your new dataset\n",
        "ann.add(Dense(units=6, activation='relu', input_dim=4))\n",
        "ann.add(Dense(units=4, activation='relu'))\n",
        "ann.add(Dense(units=2, activation='relu'))\n",
        "ann.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann.fit(x_train, y_train, batch_size=50, epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "pre = ann.predict(x_test)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre = (pre > 0.5).astype(int)\n",
        "\n",
        "acc_score = accuracy_score(y_test, pre)\n",
        "print('Accuracy of testing model is:', acc_score)\n",
        "\n",
        "\n",
        "# checking accuracy of training model\n",
        "pre1 = ann.predict(x_train)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre1 = (pre1 > 0.5).astype(int)\n",
        "\n",
        "acc_score1 = accuracy_score(y_train, pre1)\n",
        "print('Accuracy of training model is:', acc_score1)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "UfCV794chB1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Remove Overfitting`\n",
        "\n",
        "`Reduce Model Complexity:`\n",
        "\n",
        "`Smaller Networks:` A less complex network with fewer layers and neurons has less capacity to overfit.\n",
        "\n",
        "`Regularization:` Techniques like L1/L2 regularization penalize large weights in the network, discouraging the model from becoming overly reliant on specific features.\n",
        "\n",
        "`Training Process Optimization:`\n",
        "\n",
        "`Learning Rate Tuning:` A high learning rate can lead to overfitting, while a low learning rate might hinder training progress.\n",
        "\n",
        "`Improve Data Quality and Quantity:`\n",
        "\n",
        "`High-Quality Data:` Ensure you have clean, well-labeled data relevant to the task.\n",
        "\n",
        "`Data Augmentation:` Artificially increase the size and diversity of your dataset using techniques like random cropping, flipping, or adding noise. This helps the network learn more generalizable features.\n",
        "\n"
      ],
      "metadata": {
        "id": "jveyXTgnb8y-"
      }
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Create an EarlyStopping callback\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
        "\n",
        "history = ann.fit(x_train, y_train, batch_size=50, epochs=20,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks) # Pass the callback to the fit method\n",
        "\n",
        "history.history[\"accuracy\"]\n",
        "plt.plot(history.history['loss']) # Use the 'history' variable returned from the fit method\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "q8rcAfzAhZiu",
        "outputId": "14110dff-38bd-45b8-c4f0-d2b34f41d686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.7264 - accuracy: 0.6000 - val_loss: 0.7111 - val_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7251 - accuracy: 0.6000 - val_loss: 0.7114 - val_accuracy: 0.2500\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7239 - accuracy: 0.6000 - val_loss: 0.7117 - val_accuracy: 0.2500\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7226 - accuracy: 0.6000 - val_loss: 0.7120 - val_accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e0e1224e140>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Batch Normalization`\n",
        "\n",
        "A method used to make training of artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling."
      ],
      "metadata": {
        "id": "Bjt6Rb3ziswl"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AqueeqAzam/data-science-and-machine-learning-datasets/main/students-placement.csv\")\n",
        "df.head(4)\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "# Select only numerical columns for scaling\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "x = df[numerical_cols]\n",
        "\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit_transform(x)\n",
        "\n",
        "x = pd.DataFrame(ss.fit_transform(x), columns=x.columns)\n",
        "x\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "ann = Sequential()\n",
        "# Update input_dim to match the number of features in your new dataset\n",
        "ann.add(layers.Dense(units=6, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))\n",
        "ann.add(BatchNormalization())\n",
        "\n",
        "ann.add(layers.Dense(units=6, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))\n",
        "ann.add(BatchNormalization())\n",
        "\n",
        "ann.add(layers.Dense(units=6, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))\n",
        "ann.add(BatchNormalization())\n",
        "\n",
        "ann.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann.fit(x_train, y_train, batch_size=50, epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "pre = ann.predict(x_test)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre = (pre > 0.5).astype(int)\n",
        "\n",
        "acc_score = accuracy_score(y_test, pre)\n",
        "print('Accuracy of testing model is:', acc_score)\n",
        "\n",
        "\n",
        "# checking accuracy of training model\n",
        "pre1 = ann.predict(x_train)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "pre1 = (pre1 > 0.5).astype(int)\n",
        "\n",
        "acc_score1 = accuracy_score(y_train, pre1)\n",
        "print('Accuracy of training model is:', acc_score1)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "69KPIRXhk-BK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0657e5e-137b-4b6c-ccac-147c17dc66c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7518 - accuracy: 0.6000 - val_loss: 0.7785 - val_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.7391 - accuracy: 0.6667 - val_loss: 0.7805 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7282 - accuracy: 0.6667 - val_loss: 0.7825 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7173 - accuracy: 0.6667 - val_loss: 0.7846 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7066 - accuracy: 0.7333 - val_loss: 0.7867 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6959 - accuracy: 0.7333 - val_loss: 0.7888 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6854 - accuracy: 0.7333 - val_loss: 0.7909 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6756 - accuracy: 0.7333 - val_loss: 0.7930 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6661 - accuracy: 0.7333 - val_loss: 0.7950 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6568 - accuracy: 0.7333 - val_loss: 0.7971 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6476 - accuracy: 0.8000 - val_loss: 0.7992 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.8012 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6300 - accuracy: 0.8000 - val_loss: 0.8031 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6217 - accuracy: 0.8000 - val_loss: 0.8050 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6137 - accuracy: 0.8000 - val_loss: 0.8068 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6060 - accuracy: 0.8000 - val_loss: 0.8086 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5985 - accuracy: 0.8000 - val_loss: 0.8104 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5913 - accuracy: 0.8000 - val_loss: 0.8122 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5843 - accuracy: 0.8667 - val_loss: 0.8140 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5778 - accuracy: 0.8667 - val_loss: 0.8158 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "Accuracy of testing model is: 0.75\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Accuracy of training model is: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Dropout Layers`\n",
        "\n",
        "In neural networks, a dropout layer is a powerful technique used to prevent overfitting during training."
      ],
      "metadata": {
        "id": "6ruTY6HpmfAN"
      }
    },
    {
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AqueeqAzam/data-science-and-machine-learning-datasets/main/business-case-study.csv\")\n",
        "df.head(5)\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "# scaling the data\n",
        "num_col = df.select_dtypes(include=np.number).columns\n",
        "x = df[num_col]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[num_col] = scaler.fit_transform(x)\n",
        "\n",
        "# splitting the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential([\n",
        "  # Remove the Flatten layer since your input is not image data\n",
        "  layers.Dense(units=128, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "  layers.Dropout(rate=0.3),\n",
        "  layers.Dense(units=64, activation='relu'),\n",
        "  layers.Dense(units=1, activation='sigmoid')  # Use sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Use binary_crossentropy for binary classification\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO_1JktDsKDv",
        "outputId": "2adfef2c-97cb-4f64-b585-7dc35ba2caad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 106258.1094 - accuracy: 0.6726\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 27870.0352 - accuracy: 0.6729\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 13033.5449 - accuracy: 0.6740\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 10321.7090 - accuracy: 0.6730\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 6273.7349 - accuracy: 0.6814\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 7335.3887 - accuracy: 0.6729\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 5539.7798 - accuracy: 0.6640\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 3668.1064 - accuracy: 0.6715\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 1911.4436 - accuracy: 0.6762\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 1176.0658 - accuracy: 0.6754\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 245.5390 - accuracy: 0.8035\n",
            "Test accuracy: 0.8034999966621399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Vanishing Gradient Problem`\n",
        "\n",
        "`Consequences of Vanishing Gradients:`\n",
        "\n",
        "`Slow Training:` The network struggles to learn, and training can become very slow.\n",
        "`Poor Performance:` The network might not achieve optimal performance due to the limited learning in earlier layers.\n",
        "\n",
        "`Addressing Vanishing Gradients:`\n",
        "\n",
        "`Activation Functions:` Choosing activation functions that don't have vanishing gradients is crucial. ReLU (Rectified Linear Unit) is a popular choice as it has a constant gradient of 1 for positive inputs.\n"
      ],
      "metadata": {
        "id": "JT2UNuJLuG3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Hyperparameter Tuning`\n",
        "\n",
        "Hyperparameter tuning is an essential process in optimizing the performance of deep learning models, especially neural networks.\n",
        "\n",
        "Hyperparameters are settings that control the learning process of a model but are not directly learned from the training data.\n",
        "\n",
        "Examples include:\n",
        "\n",
        "`Learning rate:` Controls how much the weights of the model are updated during training.\n",
        "\n",
        "`Number of epochs:` Number of times the entire training dataset is passed through the model during training.\n",
        "\n",
        "`Network architecture: `Number and type of layers in a neural network.\n",
        "\n",
        "`Batch size:` Number of samples used to update the model's weights in each iteration.\n",
        "\n",
        "`Regularization parameters:` Techniques like L1/L2 regularization or dropout that control the complexity of the model and prevent overfitting.\n"
      ],
      "metadata": {
        "id": "QzGbeYURuwUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `CNNs`\n",
        "\n",
        "`CNNs (Convolution Neural Networks)` It is best for solving Computer Vision-related problems.\n",
        "\n",
        "\n",
        "CNN is a type of artificial neural, which is widely used for image/object recognition and classification."
      ],
      "metadata": {
        "id": "Fv8OSd-Yb8j4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Import libraries`"
      ],
      "metadata": {
        "id": "WzVas4nk0k3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras"
      ],
      "metadata": {
        "id": "gIgJhwGy3tfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Load Datasets`"
      ],
      "metadata": {
        "id": "WwuJFYPx1TX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "# ((60000, 28, 28), (60000,) ((no. of images, img_row, img_col), (labels,)\n",
        "\n",
        "# display single image\n",
        "x_train[0], y_train[0]\n",
        "\n",
        "# display image\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "x_train.ndim"
      ],
      "metadata": {
        "id": "KW8MhTVU1RAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Feature Scaling`"
      ],
      "metadata": {
        "id": "EIZPpzLh40N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "metadata": {
        "id": "XvG5k44R47x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Split Dataset`"
      ],
      "metadata": {
        "id": "yNVbd3m75M_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=10)\n",
        "\n",
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcs4AbQX5RTk",
        "outputId": "bb6c3bd0-d512-478e-847c-ede4ff423f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38400, 28, 28), (9600, 28, 28), (38400,), (9600,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CNNs model building`"
      ],
      "metadata": {
        "id": "rCliUEvy5bn2"
      }
    },
    {
      "source": [
        "model = keras.models.Sequential([keras.layers.Conv2D(\n",
        "    filters=32,\n",
        "    kernel_size=3,\n",
        "    activation='relu',\n",
        "    input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=2), # Changed 'MaxPooling2Dz' to 'MaxPooling2D'\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation='relu'),\n",
        "    keras.layers.Dense(units=10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=1, validation_data=(x_val, y_val))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbgWNzyW87MM",
        "outputId": "63189f5f-da60-40bb-b334-1727d99303b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               692352    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 693962 (2.65 MB)\n",
            "Trainable params: 693962 (2.65 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.4345 - accuracy: 0.8468 - val_loss: 0.3907 - val_accuracy: 0.8570\n",
            "Epoch 2/10\n",
            "1200/1200 [==============================] - 21s 18ms/step - loss: 0.2877 - accuracy: 0.8979 - val_loss: 0.2799 - val_accuracy: 0.8973\n",
            "Epoch 3/10\n",
            "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2388 - accuracy: 0.9133 - val_loss: 0.2580 - val_accuracy: 0.9059\n",
            "Epoch 4/10\n",
            "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2003 - accuracy: 0.9265 - val_loss: 0.2570 - val_accuracy: 0.9090\n",
            "Epoch 5/10\n",
            "1200/1200 [==============================] - 22s 18ms/step - loss: 0.1740 - accuracy: 0.9357 - val_loss: 0.2381 - val_accuracy: 0.9160\n",
            "Epoch 6/10\n",
            "1200/1200 [==============================] - 23s 19ms/step - loss: 0.1464 - accuracy: 0.9456 - val_loss: 0.2644 - val_accuracy: 0.9097\n",
            "Epoch 7/10\n",
            "1200/1200 [==============================] - 21s 18ms/step - loss: 0.1254 - accuracy: 0.9543 - val_loss: 0.2567 - val_accuracy: 0.9164\n",
            "Epoch 8/10\n",
            "1200/1200 [==============================] - 22s 19ms/step - loss: 0.1051 - accuracy: 0.9624 - val_loss: 0.2762 - val_accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "1200/1200 [==============================] - 22s 19ms/step - loss: 0.0878 - accuracy: 0.9675 - val_loss: 0.2898 - val_accuracy: 0.9152\n",
            "Epoch 10/10\n",
            "1200/1200 [==============================] - 21s 17ms/step - loss: 0.0746 - accuracy: 0.9724 - val_loss: 0.3022 - val_accuracy: 0.9175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Test model`"
      ],
      "metadata": {
        "id": "-W8EcPKtA96B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.predict(np.expand_dims(x_test[0], axis=0)).round(2)\n",
        "\n",
        "np.argmax(model.predict(np.expand_dims(x_test[0], axis=0)).round(2))\n",
        "\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQqx4fF_BAbl",
        "outputId": "68e5860a-071f-4dfc-ff4b-05ca9da40d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.3225 - accuracy: 0.9101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3225385546684265, 0.910099983215332]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Confusion Matrix`"
      ],
      "metadata": {
        "id": "dHeWNq_fDHvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "y_pred_label = [ np.argmax(label) for label in y_pred]\n",
        "cm = confusion_matrix(y_test, y_pred_label)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hL_Oau-MDLdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Classification Report`"
      ],
      "metadata": {
        "id": "asFK7rQZFZlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddPJ-QI8Fc_x",
        "outputId": "87317dcb-1435-421c-a9cf-fabd59b44d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.85      0.85      0.85      1000\n",
            "           3       0.92      0.91      0.92      1000\n",
            "           4       0.87      0.84      0.86      1000\n",
            "           5       0.97      0.98      0.98      1000\n",
            "           6       0.74      0.77      0.75      1000\n",
            "           7       0.98      0.94      0.96      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.95      0.98      0.96      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Save model`"
      ],
      "metadata": {
        "id": "aNxoh3IpF3-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('fashion_classification.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_cReJQuF7LP",
        "outputId": "7e979f1c-2a8d-4a02-d7ad-1b0cef1b918e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7K5qmg8NDHht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `RNNs`\n",
        "\n",
        "`RNNs (Recurrent Neural Networks):` It is proficient in Natural Language Processing.\n",
        "\n",
        "Mark work for Facebook in America\n",
        "\n",
        "Person -> Mark\n",
        "\n",
        "0 -> work\n",
        "\n",
        "0 -> for\n",
        "\n",
        "organization -> Facebook\n",
        "\n",
        "0 -> in\n",
        "\n",
        "location -> America\n"
      ],
      "metadata": {
        "id": "7wD8k52kcW9M"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Sequence length (number of timesteps)\n",
        "sequence_length = 10\n",
        "# Number of features in each timestep\n",
        "num_features = 4\n",
        "# Number of units in the RNN layer\n",
        "num_units = 8\n",
        "\n",
        "# Generate random data for sequences\n",
        "# Adjust the number of samples to a reasonable amount for training\n",
        "num_samples = 100\n",
        "data = tf.random.uniform((num_samples, sequence_length, num_features))\n",
        "\n",
        "# Create labels (example: predicting the sum of features at each timestep)\n",
        "y = tf.reduce_sum(data, axis=2)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "split_index = int(num_samples * 0.8)\n",
        "x_train, x_val = data[:split_index], data[split_index:]\n",
        "y_train, y_val = y[:split_index], y[split_index:]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  SimpleRNN(num_units, return_sequences=True, input_shape=(sequence_length, num_features)),  # Process entire sequence\n",
        "  SimpleRNN(num_units),  # Second RNN layer (optional)\n",
        "  Dense(1)  # Output layer (adjust for your task)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')  # Mean squared error loss for simplicity\n",
        "\n",
        "# Use the training data (x_train, y_train) and validation data (x_val, y_val)\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10)\n",
        "\n",
        "\n",
        "# New sequence for prediction\n",
        "new_data = tf.random.uniform((1, sequence_length, num_features))\n",
        "prediction = model.predict(new_data)\n",
        "print('Prediction of model is:', prediction)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxiDdIn8wmWc",
        "outputId": "8b6da316-f6e9-4b46-f2fe-dab3536377c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 6s 368ms/step - loss: 2.1942 - val_loss: 1.5685\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.6330 - val_loss: 1.2287\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.2445 - val_loss: 0.9728\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.9799 - val_loss: 0.7864\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.7981 - val_loss: 0.6507\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.6770 - val_loss: 0.5536\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5911 - val_loss: 0.4855\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.5451 - val_loss: 0.4380\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5126 - val_loss: 0.4070\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4885 - val_loss: 0.3882\n",
            "1/1 [==============================] - 1s 644ms/step\n",
            "Prediction of model is: [[1.7865866]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Have a nice day"
      ],
      "metadata": {
        "id": "fDEkJEMtwpwC"
      }
    }
  ]
}